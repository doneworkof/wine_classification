{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('train.csv')\n",
    "df.drop('id', axis=1, inplace=True)\n",
    "\n",
    "features, labels = df.drop('target', axis=1), df['target']\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(features, labels, test_size=.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9906542056074766"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rfc = RandomForestClassifier().fit(x_train, y_train)\n",
    "\n",
    "rfc.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:48:26] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\python\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "d:\\python\\lib\\site-packages\\xgboost\\data.py:262: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9906542056074766"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "xgbc = XGBClassifier().fit(x_train, y_train)\n",
    "\n",
    "xgbc.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9906542056074766"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "\n",
    "cbc = CatBoostClassifier().fit(x_train, y_train, verbose=0)\n",
    "\n",
    "cbc.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras as krs\n",
    "\n",
    "model = krs.models.Sequential([\n",
    "    krs.layers.Dense(32, activation='relu'),\n",
    "    krs.layers.Dense(64, activation='relu'),\n",
    "    krs.layers.Dense(16, activation='relu'),\n",
    "    krs.layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy'],\n",
    "    optimizer='adam'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "7/7 [==============================] - 1s 31ms/step - loss: 15.8081 - accuracy: 0.3185 - val_loss: 5.6400 - val_accuracy: 0.3645\n",
      "Epoch 2/150\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 4.6506 - accuracy: 0.2810 - val_loss: 3.5253 - val_accuracy: 0.3458\n",
      "Epoch 3/150\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 3.1132 - accuracy: 0.2506 - val_loss: 1.6842 - val_accuracy: 0.3832\n",
      "Epoch 4/150\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 1.8586 - accuracy: 0.4567 - val_loss: 1.4446 - val_accuracy: 0.4860\n",
      "Epoch 5/150\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 1.1702 - accuracy: 0.4169 - val_loss: 1.2405 - val_accuracy: 0.6075\n",
      "Epoch 6/150\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.8883 - accuracy: 0.6253 - val_loss: 0.8759 - val_accuracy: 0.5514\n",
      "Epoch 7/150\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.8026 - accuracy: 0.5878 - val_loss: 0.9692 - val_accuracy: 0.5514\n",
      "Epoch 8/150\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.7930 - accuracy: 0.6370 - val_loss: 0.8544 - val_accuracy: 0.5888\n",
      "Epoch 9/150\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.8317 - accuracy: 0.6393 - val_loss: 0.7910 - val_accuracy: 0.5607\n",
      "Epoch 10/150\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6920 - accuracy: 0.6534 - val_loss: 0.8077 - val_accuracy: 0.5794\n",
      "Epoch 11/150\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.7045 - accuracy: 0.6464 - val_loss: 0.9007 - val_accuracy: 0.5981\n",
      "Epoch 12/150\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.7039 - accuracy: 0.6557 - val_loss: 0.8696 - val_accuracy: 0.6075\n",
      "Epoch 13/150\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6810 - accuracy: 0.6581 - val_loss: 0.7424 - val_accuracy: 0.5981\n",
      "Epoch 14/150\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6536 - accuracy: 0.6745 - val_loss: 0.6906 - val_accuracy: 0.6636\n",
      "Epoch 15/150\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.6658 - accuracy: 0.6932 - val_loss: 0.6488 - val_accuracy: 0.7009\n",
      "Epoch 16/150\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.6566 - accuracy: 0.6838 - val_loss: 0.7160 - val_accuracy: 0.6075\n",
      "Epoch 17/150\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.6287 - accuracy: 0.7073 - val_loss: 0.7162 - val_accuracy: 0.5981\n",
      "Epoch 18/150\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.6686 - accuracy: 0.6628 - val_loss: 0.7601 - val_accuracy: 0.5888\n",
      "Epoch 19/150\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.6617 - accuracy: 0.6698 - val_loss: 0.6431 - val_accuracy: 0.6542\n",
      "Epoch 20/150\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.6101 - accuracy: 0.6979 - val_loss: 0.5928 - val_accuracy: 0.7383\n",
      "Epoch 21/150\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.6150 - accuracy: 0.7143 - val_loss: 0.6170 - val_accuracy: 0.7570\n",
      "Epoch 22/150\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.6367 - accuracy: 0.7143 - val_loss: 0.5864 - val_accuracy: 0.7477\n",
      "Epoch 23/150\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6618 - accuracy: 0.6792 - val_loss: 0.5659 - val_accuracy: 0.7477\n",
      "Epoch 24/150\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.5923 - accuracy: 0.7026 - val_loss: 0.5748 - val_accuracy: 0.8037\n",
      "Epoch 25/150\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.5545 - accuracy: 0.7541 - val_loss: 0.6000 - val_accuracy: 0.7477\n",
      "Epoch 26/150\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.5569 - accuracy: 0.7471 - val_loss: 0.5528 - val_accuracy: 0.7757\n",
      "Epoch 27/150\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.5464 - accuracy: 0.7611 - val_loss: 0.6049 - val_accuracy: 0.6636\n",
      "Epoch 28/150\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.5429 - accuracy: 0.7518 - val_loss: 0.5633 - val_accuracy: 0.8318\n",
      "Epoch 29/150\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.5506 - accuracy: 0.7471 - val_loss: 0.7516 - val_accuracy: 0.6168\n",
      "Epoch 30/150\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.5708 - accuracy: 0.7307 - val_loss: 0.6362 - val_accuracy: 0.6355\n",
      "Epoch 31/150\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.6546 - accuracy: 0.7190 - val_loss: 0.6050 - val_accuracy: 0.6729\n",
      "Epoch 32/150\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.6509 - accuracy: 0.7002 - val_loss: 0.5445 - val_accuracy: 0.8037\n",
      "Epoch 33/150\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6027 - accuracy: 0.7190 - val_loss: 0.5493 - val_accuracy: 0.7664\n",
      "Epoch 34/150\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.5832 - accuracy: 0.7143 - val_loss: 0.6251 - val_accuracy: 0.6542\n",
      "Epoch 35/150\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.5834 - accuracy: 0.7307 - val_loss: 0.4549 - val_accuracy: 0.8411\n",
      "Epoch 36/150\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.5430 - accuracy: 0.7564 - val_loss: 0.4521 - val_accuracy: 0.8318\n",
      "Epoch 37/150\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.5477 - accuracy: 0.7541 - val_loss: 0.4499 - val_accuracy: 0.8505\n",
      "Epoch 38/150\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.4795 - accuracy: 0.7869 - val_loss: 0.4642 - val_accuracy: 0.7944\n",
      "Epoch 39/150\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.4499 - accuracy: 0.8197 - val_loss: 0.4912 - val_accuracy: 0.7757\n",
      "Epoch 40/150\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.4282 - accuracy: 0.8220 - val_loss: 0.4128 - val_accuracy: 0.8505\n",
      "Epoch 41/150\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.3927 - accuracy: 0.8548 - val_loss: 0.4003 - val_accuracy: 0.8131\n",
      "Epoch 42/150\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.3681 - accuracy: 0.8665 - val_loss: 0.3924 - val_accuracy: 0.8411\n",
      "Epoch 43/150\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.3669 - accuracy: 0.8548 - val_loss: 0.3278 - val_accuracy: 0.9065\n",
      "Epoch 44/150\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.3899 - accuracy: 0.8220 - val_loss: 0.3201 - val_accuracy: 0.8972\n",
      "Epoch 45/150\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.3911 - accuracy: 0.8337 - val_loss: 0.4799 - val_accuracy: 0.7664\n",
      "Epoch 46/150\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.3926 - accuracy: 0.8173 - val_loss: 0.4010 - val_accuracy: 0.8131\n",
      "Epoch 47/150\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.3610 - accuracy: 0.8595 - val_loss: 0.2950 - val_accuracy: 0.8972\n",
      "Epoch 48/150\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.2975 - accuracy: 0.9016 - val_loss: 0.2920 - val_accuracy: 0.9065\n",
      "Epoch 49/150\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2925 - accuracy: 0.8946 - val_loss: 0.3382 - val_accuracy: 0.8785\n",
      "Epoch 50/150\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.2840 - accuracy: 0.9040 - val_loss: 0.2358 - val_accuracy: 0.9533\n",
      "Epoch 51/150\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.2584 - accuracy: 0.9133 - val_loss: 0.2870 - val_accuracy: 0.9065\n",
      "Epoch 52/150\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2541 - accuracy: 0.9087 - val_loss: 0.2426 - val_accuracy: 0.9346\n",
      "Epoch 53/150\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.2622 - accuracy: 0.9063 - val_loss: 0.1873 - val_accuracy: 0.9346\n",
      "Epoch 54/150\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2331 - accuracy: 0.9227 - val_loss: 0.1936 - val_accuracy: 0.9533\n",
      "Epoch 55/150\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2182 - accuracy: 0.9344 - val_loss: 0.1855 - val_accuracy: 0.9439\n",
      "Epoch 56/150\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2251 - accuracy: 0.9274 - val_loss: 0.1922 - val_accuracy: 0.9720\n",
      "Epoch 57/150\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.2183 - accuracy: 0.9227 - val_loss: 0.2268 - val_accuracy: 0.9346\n",
      "Epoch 58/150\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2299 - accuracy: 0.9133 - val_loss: 0.2053 - val_accuracy: 0.9533\n",
      "Epoch 59/150\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.2209 - accuracy: 0.9087 - val_loss: 0.1901 - val_accuracy: 0.9720\n",
      "Epoch 60/150\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2041 - accuracy: 0.9391 - val_loss: 0.1915 - val_accuracy: 0.9533\n",
      "Epoch 61/150\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2101 - accuracy: 0.9368 - val_loss: 0.2300 - val_accuracy: 0.9252\n",
      "Epoch 62/150\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2088 - accuracy: 0.9274 - val_loss: 0.1980 - val_accuracy: 0.9439\n",
      "Epoch 63/150\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2035 - accuracy: 0.9321 - val_loss: 0.2142 - val_accuracy: 0.9065\n",
      "Epoch 64/150\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.2056 - accuracy: 0.9110 - val_loss: 0.1495 - val_accuracy: 0.9720\n",
      "Epoch 65/150\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.1872 - accuracy: 0.9391 - val_loss: 0.1474 - val_accuracy: 0.9533\n",
      "Epoch 66/150\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2056 - accuracy: 0.9227 - val_loss: 0.2709 - val_accuracy: 0.8879\n",
      "Epoch 67/150\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2050 - accuracy: 0.9391 - val_loss: 0.1800 - val_accuracy: 0.9439\n",
      "Epoch 68/150\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.2172 - accuracy: 0.9133 - val_loss: 0.1480 - val_accuracy: 0.9626\n",
      "Epoch 69/150\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1989 - accuracy: 0.9227 - val_loss: 0.1957 - val_accuracy: 0.9346\n",
      "Epoch 70/150\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.1926 - accuracy: 0.9297 - val_loss: 0.1550 - val_accuracy: 0.9626\n",
      "Epoch 71/150\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1829 - accuracy: 0.9391 - val_loss: 0.2462 - val_accuracy: 0.9159\n",
      "Epoch 72/150\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1921 - accuracy: 0.9438 - val_loss: 0.1734 - val_accuracy: 0.9533\n",
      "Epoch 73/150\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1996 - accuracy: 0.9274 - val_loss: 0.1386 - val_accuracy: 0.9626\n",
      "Epoch 74/150\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.2225 - accuracy: 0.9110 - val_loss: 0.1278 - val_accuracy: 0.9813\n",
      "Epoch 75/150\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.1946 - accuracy: 0.9133 - val_loss: 0.1216 - val_accuracy: 0.9626\n",
      "Epoch 76/150\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1884 - accuracy: 0.9321 - val_loss: 0.1708 - val_accuracy: 0.9533\n",
      "Epoch 77/150\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1987 - accuracy: 0.9251 - val_loss: 0.1812 - val_accuracy: 0.9439\n",
      "Epoch 78/150\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.1937 - accuracy: 0.9274 - val_loss: 0.2211 - val_accuracy: 0.8785\n",
      "Epoch 79/150\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.2345 - accuracy: 0.9016 - val_loss: 0.1541 - val_accuracy: 0.9720\n",
      "Epoch 80/150\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.2105 - accuracy: 0.9040 - val_loss: 0.1118 - val_accuracy: 0.9813\n",
      "Epoch 81/150\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2032 - accuracy: 0.9344 - val_loss: 0.1329 - val_accuracy: 0.9626\n",
      "Epoch 82/150\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1785 - accuracy: 0.9157 - val_loss: 0.1095 - val_accuracy: 0.9720\n",
      "Epoch 83/150\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1657 - accuracy: 0.9368 - val_loss: 0.1631 - val_accuracy: 0.9720\n",
      "Epoch 84/150\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.1877 - accuracy: 0.9274 - val_loss: 0.1404 - val_accuracy: 0.9626\n",
      "Epoch 85/150\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1959 - accuracy: 0.9087 - val_loss: 0.1057 - val_accuracy: 0.9720\n",
      "Epoch 86/150\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.1596 - accuracy: 0.9438 - val_loss: 0.1476 - val_accuracy: 0.9720\n",
      "Epoch 87/150\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1639 - accuracy: 0.9344 - val_loss: 0.1131 - val_accuracy: 0.9813\n",
      "Epoch 88/150\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.1629 - accuracy: 0.9368 - val_loss: 0.1220 - val_accuracy: 0.9626\n",
      "Epoch 89/150\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1583 - accuracy: 0.9438 - val_loss: 0.1135 - val_accuracy: 0.9813\n",
      "Epoch 90/150\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1541 - accuracy: 0.9415 - val_loss: 0.1184 - val_accuracy: 0.9626\n",
      "Epoch 91/150\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1670 - accuracy: 0.9415 - val_loss: 0.1071 - val_accuracy: 0.9720\n",
      "Epoch 92/150\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2027 - accuracy: 0.9227 - val_loss: 0.1228 - val_accuracy: 0.9813\n",
      "Epoch 93/150\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1825 - accuracy: 0.9251 - val_loss: 0.2269 - val_accuracy: 0.9252\n",
      "Epoch 94/150\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1981 - accuracy: 0.9180 - val_loss: 0.1519 - val_accuracy: 0.9439\n",
      "Epoch 95/150\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.1780 - accuracy: 0.9344 - val_loss: 0.1183 - val_accuracy: 0.9626\n",
      "Epoch 96/150\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2051 - accuracy: 0.9251 - val_loss: 0.1366 - val_accuracy: 0.9626\n",
      "Epoch 97/150\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1810 - accuracy: 0.9274 - val_loss: 0.1099 - val_accuracy: 0.9813\n",
      "Epoch 98/150\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1713 - accuracy: 0.9415 - val_loss: 0.1184 - val_accuracy: 0.9720\n",
      "Epoch 99/150\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1708 - accuracy: 0.9321 - val_loss: 0.1474 - val_accuracy: 0.9720\n",
      "Epoch 100/150\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1725 - accuracy: 0.9204 - val_loss: 0.1882 - val_accuracy: 0.9252\n",
      "Epoch 101/150\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1819 - accuracy: 0.9321 - val_loss: 0.1110 - val_accuracy: 0.9626\n",
      "Epoch 102/150\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.1845 - accuracy: 0.9391 - val_loss: 0.1368 - val_accuracy: 0.9626\n",
      "Epoch 103/150\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.2027 - accuracy: 0.9110 - val_loss: 0.1010 - val_accuracy: 0.9813\n",
      "Epoch 104/150\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2074 - accuracy: 0.8993 - val_loss: 0.2221 - val_accuracy: 0.8692\n",
      "Epoch 105/150\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1889 - accuracy: 0.9180 - val_loss: 0.1278 - val_accuracy: 0.9720\n",
      "Epoch 106/150\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1688 - accuracy: 0.9274 - val_loss: 0.0938 - val_accuracy: 0.9720\n",
      "Epoch 107/150\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1684 - accuracy: 0.9321 - val_loss: 0.1120 - val_accuracy: 0.9626\n",
      "Epoch 108/150\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1608 - accuracy: 0.9438 - val_loss: 0.1021 - val_accuracy: 0.9720\n",
      "Epoch 109/150\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1519 - accuracy: 0.9344 - val_loss: 0.1778 - val_accuracy: 0.9252\n",
      "Epoch 110/150\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.1595 - accuracy: 0.9461 - val_loss: 0.1011 - val_accuracy: 0.9720\n",
      "Epoch 111/150\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.1421 - accuracy: 0.9508 - val_loss: 0.0986 - val_accuracy: 0.9720\n",
      "Epoch 112/150\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1629 - accuracy: 0.9391 - val_loss: 0.1553 - val_accuracy: 0.9346\n",
      "Epoch 113/150\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.1657 - accuracy: 0.9368 - val_loss: 0.1473 - val_accuracy: 0.9626\n",
      "Epoch 114/150\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1572 - accuracy: 0.9485 - val_loss: 0.0936 - val_accuracy: 0.9720\n",
      "Epoch 115/150\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1537 - accuracy: 0.9391 - val_loss: 0.1091 - val_accuracy: 0.9720\n",
      "Epoch 116/150\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1356 - accuracy: 0.9438 - val_loss: 0.0976 - val_accuracy: 0.9813\n",
      "Epoch 117/150\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1532 - accuracy: 0.9438 - val_loss: 0.1231 - val_accuracy: 0.9626\n",
      "Epoch 118/150\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1448 - accuracy: 0.9508 - val_loss: 0.1028 - val_accuracy: 0.9813\n",
      "Epoch 119/150\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1495 - accuracy: 0.9415 - val_loss: 0.1542 - val_accuracy: 0.9533\n",
      "Epoch 120/150\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.1620 - accuracy: 0.9415 - val_loss: 0.1215 - val_accuracy: 0.9626\n",
      "Epoch 121/150\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.1596 - accuracy: 0.9297 - val_loss: 0.0935 - val_accuracy: 0.9813\n",
      "Epoch 122/150\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1679 - accuracy: 0.9368 - val_loss: 0.1293 - val_accuracy: 0.9626\n",
      "Epoch 123/150\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1617 - accuracy: 0.9391 - val_loss: 0.1022 - val_accuracy: 0.9626\n",
      "Epoch 124/150\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1567 - accuracy: 0.9391 - val_loss: 0.1181 - val_accuracy: 0.9813\n",
      "Epoch 125/150\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.1430 - accuracy: 0.9368 - val_loss: 0.1282 - val_accuracy: 0.9720\n",
      "Epoch 126/150\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1686 - accuracy: 0.9227 - val_loss: 0.0915 - val_accuracy: 0.9720\n",
      "Epoch 127/150\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1399 - accuracy: 0.9485 - val_loss: 0.1225 - val_accuracy: 0.9626\n",
      "Epoch 128/150\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1580 - accuracy: 0.9391 - val_loss: 0.0928 - val_accuracy: 0.9813\n",
      "Epoch 129/150\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.1653 - accuracy: 0.9344 - val_loss: 0.1837 - val_accuracy: 0.9159\n",
      "Epoch 130/150\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.1482 - accuracy: 0.9415 - val_loss: 0.0898 - val_accuracy: 0.9813\n",
      "Epoch 131/150\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1410 - accuracy: 0.9508 - val_loss: 0.1129 - val_accuracy: 0.9813\n",
      "Epoch 132/150\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.1342 - accuracy: 0.9391 - val_loss: 0.1038 - val_accuracy: 0.9813\n",
      "Epoch 133/150\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1389 - accuracy: 0.9625 - val_loss: 0.1509 - val_accuracy: 0.9533\n",
      "Epoch 134/150\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1575 - accuracy: 0.9368 - val_loss: 0.1009 - val_accuracy: 0.9813\n",
      "Epoch 135/150\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1750 - accuracy: 0.9368 - val_loss: 0.1503 - val_accuracy: 0.9533\n",
      "Epoch 136/150\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1681 - accuracy: 0.9297 - val_loss: 0.1698 - val_accuracy: 0.9346\n",
      "Epoch 137/150\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1697 - accuracy: 0.9415 - val_loss: 0.1006 - val_accuracy: 0.9813\n",
      "Epoch 138/150\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1641 - accuracy: 0.9344 - val_loss: 0.1227 - val_accuracy: 0.9720\n",
      "Epoch 139/150\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.1392 - accuracy: 0.9485 - val_loss: 0.0948 - val_accuracy: 0.9720\n",
      "Epoch 140/150\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1427 - accuracy: 0.9485 - val_loss: 0.1222 - val_accuracy: 0.9626\n",
      "Epoch 141/150\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.1359 - accuracy: 0.9508 - val_loss: 0.1003 - val_accuracy: 0.9813\n",
      "Epoch 142/150\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.1326 - accuracy: 0.9438 - val_loss: 0.1133 - val_accuracy: 0.9720\n",
      "Epoch 143/150\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.1457 - accuracy: 0.9415 - val_loss: 0.0931 - val_accuracy: 0.9720\n",
      "Epoch 144/150\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1557 - accuracy: 0.9368 - val_loss: 0.1076 - val_accuracy: 0.9626\n",
      "Epoch 145/150\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1407 - accuracy: 0.9461 - val_loss: 0.0973 - val_accuracy: 0.9813\n",
      "Epoch 146/150\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1288 - accuracy: 0.9555 - val_loss: 0.1156 - val_accuracy: 0.9813\n",
      "Epoch 147/150\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.1290 - accuracy: 0.9625 - val_loss: 0.1044 - val_accuracy: 0.9626\n",
      "Epoch 148/150\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.1636 - accuracy: 0.9368 - val_loss: 0.1040 - val_accuracy: 0.9813\n",
      "Epoch 149/150\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.1353 - accuracy: 0.9532 - val_loss: 0.1096 - val_accuracy: 0.9813\n",
      "Epoch 150/150\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1280 - accuracy: 0.9532 - val_loss: 0.0923 - val_accuracy: 0.9813\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x25506168820>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs=150, batch_size=64, validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 6ms/step - loss: 0.0923 - accuracy: 0.9813\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.09229278564453125, 0.9813084006309509]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "865d8b2eb28e274047ba64063dfb6a2aabf0dfec4905d304d7a76618dae6fdd4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
